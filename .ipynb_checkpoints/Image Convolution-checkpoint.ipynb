{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4713b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 6, 6)\n",
      "(1, 1, 3, 3)\n",
      "9\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, Normalize\n",
    "\n",
    "from data_generation.image_classification import generate_dataset\n",
    "from helpers import index_splitter, make_balanced_sampler\n",
    "from beguinnersGuide2_1 import StepByStep\n",
    "\n",
    "\n",
    "#'Convolution'\n",
    "single = np.array(\n",
    "    [[[[5, 0, 8, 7, 8, 1],\n",
    "       [1, 9, 5, 0, 7, 7],\n",
    "       [6, 0, 2, 4, 6, 6],\n",
    "       [9, 7, 6, 6, 8, 4],\n",
    "       [8, 3, 8, 5, 1, 3],\n",
    "       [7, 2, 7, 0, 1, 0]]]]\n",
    ")\n",
    "print(single.shape)\n",
    "\n",
    "identity = np.array(\n",
    "    [[[[0, 0, 0],\n",
    "       [0, 1, 0],\n",
    "       [0, 0, 0]]]]\n",
    ")\n",
    "print(identity.shape)\n",
    "\n",
    "region = single[:, :, 0:3, 0:3]\n",
    "filtered_region = region * identity\n",
    "total = filtered_region.sum()\n",
    "print(total)\n",
    "\n",
    "new_region = single[:, :, 0:3, (0+1):(3+1)]\n",
    "new_region_filter = new_region * identity\n",
    "print(new_region_filter.sum())\n",
    "\n",
    "# given an Image of hi x wi and filter hf x wf\n",
    "# the convolution will result in the image iof size - (hi + 1 - hf, wi +1 - wf)\n",
    "# this size is lesser than the image so\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692a45e",
   "metadata": {},
   "source": [
    "# Convolving in PyTorch\n",
    "\n",
    "#### Filter/Kernels\n",
    "![](./images/conv1.png)\n",
    "\n",
    "\n",
    "$$\n",
    "\\Large\n",
    "(h_i, w_i) * f = (h_i - f + 1, w_i - f + 1)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c719724",
   "metadata": {},
   "source": [
    "##### Use padding with zero if want to keep the image size same as the input image\n",
    "##### In torch conv can be a function and also a learnable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca705579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[9., 5., 0., 7.],\n",
       "          [0., 2., 4., 6.],\n",
       "          [7., 6., 6., 8.],\n",
       "          [3., 8., 5., 1.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple function\n",
    "original_image = torch.as_tensor(single).float()\n",
    "kernel = torch.as_tensor(identity).float()\n",
    "covolution_result = F.conv2d(original_image, kernel,  stride=1)\n",
    "covolution_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a3a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
